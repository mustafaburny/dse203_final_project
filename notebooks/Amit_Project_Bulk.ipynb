{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "offshore-priest",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install py2neo\n",
    "#!pip install nlp_rake\n",
    "#!pip install pytextrank\n",
    "#!python3 -m pip install -U pip\n",
    "#!python3 -m pip install -r requirements.txt\n",
    "#!python3 -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "structural-number",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from py2neo import Graph,Node,Relationship\n",
    "from py2neo.bulk import create_nodes\n",
    "import re\n",
    "from py2neo.bulk import create_relationships\n",
    "import nltk\n",
    "import re\n",
    "import collections "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "applied-franchise",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read Reddit post on wallstreetbets subreddit\n",
    "df_p = pd.read_csv('archive/wsb-aug-2021-posts.csv', usecols=None,names=['type', 'p_id', 'subid',\n",
    "                    'name', 'nsfw','p_created','p_permalink','domain','url','selftext','p_title','p_score'],skiprows=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "marked-puppy",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25751, 5)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Retain relevant columns\n",
    "df_p = df_p[['p_id','p_created','p_permalink','p_title','p_score']]\n",
    "df_p.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "figured-tracy",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read Comments to reddit posts file\n",
    "df_c = pd.read_csv('archive/wsb-aug-2021-comments.csv', usecols=None, names=['type', 'c_id', 'subid',\n",
    "                    'name', 'nsfw','c_created','c_permalink','c_body','c_sentiment','c_score'],skiprows=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "spoken-commitment",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1001160, 6)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Retain relevant columns\n",
    "df_c=df_c[['c_id','c_created','c_permalink','c_body','c_score']]\n",
    "df_c['parentid']=df_c.c_permalink.str.slice(49,55) # Extract original post id from permalink\n",
    "df_c.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "thousand-scientist",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>p_id</th>\n",
       "      <th>p_created</th>\n",
       "      <th>p_permalink</th>\n",
       "      <th>p_title</th>\n",
       "      <th>p_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>pfi0x7</td>\n",
       "      <td>1630454321</td>\n",
       "      <td>https://old.reddit.com/r/wallstreetbets/commen...</td>\n",
       "      <td>Is BABA the next?</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>pfhz92</td>\n",
       "      <td>1630454157</td>\n",
       "      <td>https://old.reddit.com/r/wallstreetbets/commen...</td>\n",
       "      <td>$TELL- According to Wall Street Journal its a ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>pfhxzc</td>\n",
       "      <td>1630454028</td>\n",
       "      <td>https://old.reddit.com/r/wallstreetbets/commen...</td>\n",
       "      <td>IS BABA next?</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>pfhw6s</td>\n",
       "      <td>1630453851</td>\n",
       "      <td>https://old.reddit.com/r/wallstreetbets/commen...</td>\n",
       "      <td>1.4K to 7.K overnight on FIVN puts. Thanks ZM!</td>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>pfhtyf</td>\n",
       "      <td>1630453627</td>\n",
       "      <td>https://old.reddit.com/r/wallstreetbets/commen...</td>\n",
       "      <td>1.4K to 7.1K overnight on FIVN puts. Thanks ZM!</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     p_id   p_created                                        p_permalink  \\\n",
       "0  pfi0x7  1630454321  https://old.reddit.com/r/wallstreetbets/commen...   \n",
       "1  pfhz92  1630454157  https://old.reddit.com/r/wallstreetbets/commen...   \n",
       "2  pfhxzc  1630454028  https://old.reddit.com/r/wallstreetbets/commen...   \n",
       "3  pfhw6s  1630453851  https://old.reddit.com/r/wallstreetbets/commen...   \n",
       "4  pfhtyf  1630453627  https://old.reddit.com/r/wallstreetbets/commen...   \n",
       "\n",
       "                                             p_title  p_score  \n",
       "0                                  Is BABA the next?        1  \n",
       "1  $TELL- According to Wall Street Journal its a ...        1  \n",
       "2                                      IS BABA next?        1  \n",
       "3     1.4K to 7.K overnight on FIVN puts. Thanks ZM!       79  \n",
       "4    1.4K to 7.1K overnight on FIVN puts. Thanks ZM!        2  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_p.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "announced-spotlight",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>c_id</th>\n",
       "      <th>c_created</th>\n",
       "      <th>c_permalink</th>\n",
       "      <th>c_body</th>\n",
       "      <th>c_score</th>\n",
       "      <th>parentid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hb4hdm3</td>\n",
       "      <td>1630454394</td>\n",
       "      <td>https://old.reddit.com/r/wallstreetbets/commen...</td>\n",
       "      <td>What's updog</td>\n",
       "      <td>3</td>\n",
       "      <td>pfdkjw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hb4hdm8</td>\n",
       "      <td>1630454394</td>\n",
       "      <td>https://old.reddit.com/r/wallstreetbets/commen...</td>\n",
       "      <td>Don’t tell em</td>\n",
       "      <td>1</td>\n",
       "      <td>pfdkjw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hb4hdjc</td>\n",
       "      <td>1630454393</td>\n",
       "      <td>https://old.reddit.com/r/wallstreetbets/commen...</td>\n",
       "      <td>I realize this, ive been losing thousands shoo...</td>\n",
       "      <td>2</td>\n",
       "      <td>pfdkjw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>hb4hdgo</td>\n",
       "      <td>1630454392</td>\n",
       "      <td>https://old.reddit.com/r/wallstreetbets/commen...</td>\n",
       "      <td>then it tanks after earnings</td>\n",
       "      <td>4</td>\n",
       "      <td>pfgr1h</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>hb4hdeh</td>\n",
       "      <td>1630454391</td>\n",
       "      <td>https://old.reddit.com/r/wallstreetbets/commen...</td>\n",
       "      <td>Are you saying I should or shouldn’t yolo my l...</td>\n",
       "      <td>1</td>\n",
       "      <td>pf3xee</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      c_id   c_created                                        c_permalink  \\\n",
       "0  hb4hdm3  1630454394  https://old.reddit.com/r/wallstreetbets/commen...   \n",
       "1  hb4hdm8  1630454394  https://old.reddit.com/r/wallstreetbets/commen...   \n",
       "2  hb4hdjc  1630454393  https://old.reddit.com/r/wallstreetbets/commen...   \n",
       "3  hb4hdgo  1630454392  https://old.reddit.com/r/wallstreetbets/commen...   \n",
       "4  hb4hdeh  1630454391  https://old.reddit.com/r/wallstreetbets/commen...   \n",
       "\n",
       "                                              c_body  c_score parentid  \n",
       "0                                       What's updog        3   pfdkjw  \n",
       "1                                      Don’t tell em        1   pfdkjw  \n",
       "2  I realize this, ive been losing thousands shoo...        2   pfdkjw  \n",
       "3                       then it tanks after earnings        4   pfgr1h  \n",
       "4  Are you saying I should or shouldn’t yolo my l...        1   pf3xee  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_c.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "neutral-television",
   "metadata": {},
   "source": [
    "### Data Cleanup and merging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "floppy-italy",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((25751, 5), (1001160, 6))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_p.shape, df_c.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "million-visitor",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dropping null values\n",
    "df_c.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "regulation-insured",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((25751, 5), (1001158, 6))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_p.shape, df_c.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "caring-python",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((25751, 5), (857417, 6))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dropping rows with body and title as [removed]\n",
    "df_p=df_p[~df_p.p_title.str.match(pat='\\[?removed\\]')]\n",
    "df_c=df_c[~df_c.c_body.str.match(pat='\\[?removed\\]')]\n",
    "df_p.shape,df_c.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "attempted-preservation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((25751, 5), (813950, 6))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dropping rows with body and title as [deleted]\n",
    "df_p=df_p[~df_p.p_title.str.match(pat='\\[?deleted\\]')]\n",
    "df_c=df_c[~df_c.c_body.str.match(pat='\\[?deleted\\]')]\n",
    "df_p.shape,df_c.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "interstate-blank",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_m=df_p.merge(df_c, left_on='p_id', right_on='parentid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "younger-hazard",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(799702, 11)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_m.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "underlying-cartridge",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of final dataframe after data cleanup (783773, 11)\n"
     ]
    }
   ],
   "source": [
    "# Dropping rows with body and title as containing string 'Your submission was removed'\n",
    "df_m=df_m[~df_m.c_body.str.contains('Your submission was removed')]\n",
    "df_m=df_m[~df_m.c_body.str.contains('Your submission was removed')]\n",
    "print('Shape of final dataframe after data cleanup',df_m.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "assured-keeping",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>p_id</th>\n",
       "      <th>p_created</th>\n",
       "      <th>p_permalink</th>\n",
       "      <th>p_title</th>\n",
       "      <th>p_score</th>\n",
       "      <th>c_id</th>\n",
       "      <th>c_created</th>\n",
       "      <th>c_permalink</th>\n",
       "      <th>c_body</th>\n",
       "      <th>c_score</th>\n",
       "      <th>parentid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>pfhw6s</td>\n",
       "      <td>1630453851</td>\n",
       "      <td>https://old.reddit.com/r/wallstreetbets/commen...</td>\n",
       "      <td>1.4K to 7.K overnight on FIVN puts. Thanks ZM!</td>\n",
       "      <td>79</td>\n",
       "      <td>hb4grlq</td>\n",
       "      <td>1630454109</td>\n",
       "      <td>https://old.reddit.com/r/wallstreetbets/commen...</td>\n",
       "      <td>How do people do this?</td>\n",
       "      <td>4</td>\n",
       "      <td>pfhw6s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>pfhw6s</td>\n",
       "      <td>1630453851</td>\n",
       "      <td>https://old.reddit.com/r/wallstreetbets/commen...</td>\n",
       "      <td>1.4K to 7.K overnight on FIVN puts. Thanks ZM!</td>\n",
       "      <td>79</td>\n",
       "      <td>hb4ga59</td>\n",
       "      <td>1630453885</td>\n",
       "      <td>https://old.reddit.com/r/wallstreetbets/commen...</td>\n",
       "      <td>\\n**User Report**| | | |\\n:--|:--|:--|:--\\n**T...</td>\n",
       "      <td>1</td>\n",
       "      <td>pfhw6s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>pfhtyf</td>\n",
       "      <td>1630453627</td>\n",
       "      <td>https://old.reddit.com/r/wallstreetbets/commen...</td>\n",
       "      <td>1.4K to 7.1K overnight on FIVN puts. Thanks ZM!</td>\n",
       "      <td>2</td>\n",
       "      <td>hb4ft1v</td>\n",
       "      <td>1630453666</td>\n",
       "      <td>https://old.reddit.com/r/wallstreetbets/commen...</td>\n",
       "      <td>\\n**User Report**| | | |\\n:--|:--|:--|:--\\n**T...</td>\n",
       "      <td>1</td>\n",
       "      <td>pfhtyf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>pfhtyf</td>\n",
       "      <td>1630453627</td>\n",
       "      <td>https://old.reddit.com/r/wallstreetbets/commen...</td>\n",
       "      <td>1.4K to 7.1K overnight on FIVN puts. Thanks ZM!</td>\n",
       "      <td>2</td>\n",
       "      <td>hb4fs9a</td>\n",
       "      <td>1630453655</td>\n",
       "      <td>https://old.reddit.com/r/wallstreetbets/commen...</td>\n",
       "      <td>I am a bot from /r/wallstreetbets. You submitt...</td>\n",
       "      <td>1</td>\n",
       "      <td>pfhtyf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>pfhq3j</td>\n",
       "      <td>1630453246</td>\n",
       "      <td>https://old.reddit.com/r/wallstreetbets/commen...</td>\n",
       "      <td>Does anyone know what the first stock symbol i...</td>\n",
       "      <td>4</td>\n",
       "      <td>hb4gzf2</td>\n",
       "      <td>1630454210</td>\n",
       "      <td>https://old.reddit.com/r/wallstreetbets/commen...</td>\n",
       "      <td>That company was delisted, the value is prob a...</td>\n",
       "      <td>3</td>\n",
       "      <td>pfhq3j</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     p_id   p_created                                        p_permalink  \\\n",
       "0  pfhw6s  1630453851  https://old.reddit.com/r/wallstreetbets/commen...   \n",
       "1  pfhw6s  1630453851  https://old.reddit.com/r/wallstreetbets/commen...   \n",
       "2  pfhtyf  1630453627  https://old.reddit.com/r/wallstreetbets/commen...   \n",
       "3  pfhtyf  1630453627  https://old.reddit.com/r/wallstreetbets/commen...   \n",
       "4  pfhq3j  1630453246  https://old.reddit.com/r/wallstreetbets/commen...   \n",
       "\n",
       "                                             p_title  p_score     c_id  \\\n",
       "0     1.4K to 7.K overnight on FIVN puts. Thanks ZM!       79  hb4grlq   \n",
       "1     1.4K to 7.K overnight on FIVN puts. Thanks ZM!       79  hb4ga59   \n",
       "2    1.4K to 7.1K overnight on FIVN puts. Thanks ZM!        2  hb4ft1v   \n",
       "3    1.4K to 7.1K overnight on FIVN puts. Thanks ZM!        2  hb4fs9a   \n",
       "4  Does anyone know what the first stock symbol i...        4  hb4gzf2   \n",
       "\n",
       "    c_created                                        c_permalink  \\\n",
       "0  1630454109  https://old.reddit.com/r/wallstreetbets/commen...   \n",
       "1  1630453885  https://old.reddit.com/r/wallstreetbets/commen...   \n",
       "2  1630453666  https://old.reddit.com/r/wallstreetbets/commen...   \n",
       "3  1630453655  https://old.reddit.com/r/wallstreetbets/commen...   \n",
       "4  1630454210  https://old.reddit.com/r/wallstreetbets/commen...   \n",
       "\n",
       "                                              c_body  c_score parentid  \n",
       "0                             How do people do this?        4   pfhw6s  \n",
       "1  \\n**User Report**| | | |\\n:--|:--|:--|:--\\n**T...        1   pfhw6s  \n",
       "2  \\n**User Report**| | | |\\n:--|:--|:--|:--\\n**T...        1   pfhtyf  \n",
       "3  I am a bot from /r/wallstreetbets. You submitt...        1   pfhtyf  \n",
       "4  That company was delisted, the value is prob a...        3   pfhq3j  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_p.reset_index(inplace=True,drop=True)\n",
    "df_c.reset_index(inplace=True,drop=True)\n",
    "df_m.reset_index(inplace=True,drop=True)\n",
    "df_m.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "extreme-referral",
   "metadata": {},
   "source": [
    "### Most popular Post"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "expired-velvet",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most popular posts is ['My portfolio after discovering wsb'] \n",
      "with the score of 45414\n"
     ]
    }
   ],
   "source": [
    "print(f'''Most popular posts is {df_p[df_p.p_score == df_p.p_score.max()].p_title.values} \n",
    "with the score of {df_p.p_score.max()}''')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "brown-acting",
   "metadata": {},
   "source": [
    "### Most popular Comment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "intense-convenience",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most popular posts is ['Ok so I\\'d just remove the letter \"k\" from the post because if you do that then you\\'ll only be down $15 instead of $15k, and that\\'s a really manageable loss.'] \n",
      "      with the score of 21129\n"
     ]
    }
   ],
   "source": [
    "print(f'''Most popular posts is {df_c[df_c.c_score == df_c.c_score.max()].c_body.values} \n",
    "      with the score of {df_c.c_score.max()}''')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "controversial-afghanistan",
   "metadata": {},
   "source": [
    "### Most commented post"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "forced-developer",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most commented post is: Weekend Discussion Thread for the Weekend of August 13, 2021\n"
     ]
    }
   ],
   "source": [
    "a=df_m['parentid'].mode()\n",
    "title=df_m.p_title[df_m.p_id == 'p3sv76']\n",
    "print(f'Most commented post is: {title[title.index[0]]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "conservative-liability",
   "metadata": {},
   "source": [
    "## Keyword Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "refined-webmaster",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We had a problem of scale. Running any line below was not possible for 1M+ records so we decided to curtail our dataset\n",
    "\n",
    "v = df_m.p_id.value_counts()\n",
    "df_m=df_m[df_m.p_id.isin(v.index[v.gt(15000)])]\n",
    "df_m.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "partial-fault",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(71732, 11)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_m.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "suspected-portugal",
   "metadata": {},
   "source": [
    "### Using RAKE (We decided to use rack over spacy for better output and performance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "reflected-spare",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/asachan/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Download stopwords\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "rough-frost",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nlp_rake import Rake\n",
    "r = Rake(\n",
    "    min_chars=2,\n",
    "    max_words=5,\n",
    "    min_freq=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "graduate-grant",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of unique posts:  4\n",
      "Length of unique titles:  19259\n"
     ]
    }
   ],
   "source": [
    "posts = df_m.p_title.unique()\n",
    "titles = df_m.c_body.unique()\n",
    "print('Length of unique posts: ',len(posts))\n",
    "print('Length of unique titles: ',len(title))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "brave-stand",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of keywords extracted: 0\n",
      "CPU times: user 30.8 ms, sys: 2.49 ms, total: 33.3 ms\n",
      "Wall time: 31.7 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Get all stock symbol from title of the post.\n",
    "title_ent=[]\n",
    "for i in range(len(posts)):   \n",
    "    keywords = r.apply(posts[i])\n",
    "    if len(keywords) > 0:\n",
    "        result = re.search(\"\\$(\\w+)\", keywords[0][0])\n",
    "        if result:\n",
    "            title_ent.append(result.group(1))\n",
    "print('Number of keywords extracted:', len(title_ent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "external-hungarian",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of keywords extracted: 783\n",
      "CPU times: user 6min 14s, sys: 2.38 s, total: 6min 17s\n",
      "Wall time: 6min 18s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Get all stock symbol from the body of the comments.\n",
    "body_ent=[]\n",
    "for i in range(len(titles)):    \n",
    "    keywords = r.apply(titles[i])\n",
    "    if len(keywords) > 0:\n",
    "        result = re.search(\"\\$(\\w+)\", keywords[0][0])\n",
    "        if result:\n",
    "            body_ent.append(result.group(1))\n",
    "print('Number of keywords extracted:', len(body_ent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "vocational-navigator",
   "metadata": {},
   "outputs": [],
   "source": [
    "m_com=[]\n",
    "for i in range(len(body_ent)):\n",
    "    if body_ent[i].isalpha():\n",
    "        m_com.append(body_ent[i])\n",
    "m_com=set(m_com)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "breeding-patient",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of companies mentioned 124\n"
     ]
    }
   ],
   "source": [
    "print('Number of companies mentioned',len(m_com))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adjustable-columbia",
   "metadata": {},
   "source": [
    "### Using pytextrank and spacy (Output especially with '$' prefixed string is not as good as RACK)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "micro-nothing",
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://towardsdatascience.com/keyword-extraction-a-benchmark-of-7-algorithms-in-python-8a905326d93f - Keyword extraction comparison\n",
    "# import pytextrank\n",
    "# import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "musical-ensemble",
   "metadata": {},
   "outputs": [],
   "source": [
    "# nlp = spacy.load(\"en_core_web_sm\")\n",
    "# nlp.add_pipe(\"textrank\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "suspended-energy",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# ## Extract keywords from title of the post\n",
    "# p_ent=[]\n",
    "# for i in range(len(df_p)):\n",
    "#     doc=nlp(df_p.p_title[i])\n",
    "#     for ent in doc.ents:\n",
    "#         p_ent.append(ent.text) # named entity and noun chunk yields same result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "gothic-acrylic",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# ## Extract keywords from body of the comments\n",
    "# c_ent=[]\n",
    "# for i in range(len(df_c)):\n",
    "#     doc=nlp(df_c.c_body[i])\n",
    "#     for ent in doc.ents:\n",
    "#         c_ent.append(ent.text) # named entity and noun chunk yields same result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "governing-scanner",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "after-advocacy",
   "metadata": {},
   "source": [
    "## Graph Section"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "commercial-return",
   "metadata": {},
   "source": [
    "#### Project and dabase was manually created"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "several-wheat",
   "metadata": {},
   "outputs": [],
   "source": [
    "g = Graph(\"bolt://localhost:11006\", auth=('neo4j', 'admin'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "permanent-slide",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create Post nodes\n",
    "# data=[]\n",
    "# posts=df_p\n",
    "# for i in range(len(posts)):\n",
    "#     x=posts.id[i]\n",
    "#     y=posts.title[i]\n",
    "#     z=str(posts.score[i])\n",
    "#     dict1 = {'id':x, 'title':y, 'score':z}\n",
    "#     data.append(dict1)\n",
    "# create_nodes(g.auto(), data, labels={\"Post\"})\n",
    "\n",
    "# #Create comments nodes\n",
    "# data=[]\n",
    "# comments=df_c\n",
    "# for i in range(len(comments)):\n",
    "#     x=comments.id[i]\n",
    "#     y=comments.body[i]\n",
    "#     z=str(comments.score[i])\n",
    "#     zz=comments.parentid[i]\n",
    "#     dict1 = {'id':x, 'title':y, 'score':z,'parentid':zz}\n",
    "#     data.append(dict1)\n",
    "\n",
    "# from itertools import islice\n",
    "# stream = iter(data)\n",
    "# batch_size = 10000\n",
    "# while True:\n",
    "#     batch = islice(stream, batch_size)\n",
    "#     if batch:\n",
    "#         create_nodes(g.auto(), batch, labels={\"Comment\"})\n",
    "#     else:\n",
    "#         break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "casual-bryan",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# This code creates nodes and relationship between nodes\n",
    "for i in range(len(df_m)):\n",
    "\n",
    "    a = Node(\"POST\", p_id=df_m.p_id[i], title=df_m.p_title[i], score=str(df_m.p_score[i]))\n",
    "    a.__primarylabel__ = \"POST\"\n",
    "    a.__primarykey__ = \"p_id\"\n",
    "    b = Node(\"COMMENT\", c_id=df_m.c_id[i], body=df_m.c_body[i], score=str(df_m.c_score[i]), parentid=df_m.parentid[i])\n",
    "    b.__primarylabel__ = \"COMMENT\"\n",
    "    b.__primarykey__ = \"c_id\"\n",
    "    HAS = Relationship.type(\"HAS\")\n",
    "    g.merge(HAS(a, b)) # Relations between post and comment\n",
    "    keywords = r.apply(df_m.c_body[i])\n",
    "    m_com=[]\n",
    "    if len(keywords) > 0:\n",
    "        result = re.search(\"\\$(\\w+)\", keywords[0][0])\n",
    "        if result:\n",
    "            m_com.append(result.group(1))\n",
    "\n",
    "    for i in m_com:\n",
    "        c = Node(\"Company\", name=i)\n",
    "        c.__primarylabel__ = \"Company\"\n",
    "        c.__primarykey__ = \"name\"\n",
    "        MENTIONS = Relationship.type(\"MENTIONS\")\n",
    "        g.merge(MENTIONS(b, c)) # Relations between comment and companies mentioned\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "quiet-ordinance",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['pcuv2j', 'p8cqpr', 'p3sv76', 'ozebic'], dtype=object)"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_m.p_id.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "humanitarian-happiness",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caring-wellington",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "spatial-briefs",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Using Bulk method\n",
    "# from py2neo import Graph\n",
    "# from py2neo.bulk import create_relationships\n",
    "# d=data[0:5]\n",
    "# from itertools import islice\n",
    "# stream = iter(d)\n",
    "# batch_size = 10000\n",
    "# while True:\n",
    "#     batch = islice(stream, batch_size)\n",
    "#     if batch:\n",
    "#         create_relationships(g.auto(), batch, \"HAS\", \\\n",
    "#     start_node_key=(\"Post\", \"id\", \"title\",\"score\"), end_node_key=(\"Comment\", \"id\",\"body\",\"score\",\"parentid\"))\n",
    "#     else:\n",
    "#         break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unable-knitting",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "immediate-timer",
   "metadata": {},
   "outputs": [],
   "source": [
    "g.delete_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "better-bread",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g.nodes.match(\"POST\").count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stuffed-monster",
   "metadata": {},
   "outputs": [],
   "source": [
    "g.nodes.match(\"Comment\").count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "employed-determination",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "civil-benefit",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "weekly-course",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "welcome-typing",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lonely-subscription",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "toxic-collect",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "attractive-distance",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "activated-candy",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "intermediate-electron",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "increasing-sequence",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "saved-heather",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "scientific-malawi",
   "metadata": {},
   "source": [
    "### Pulling stock price data from finance.yahoo.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "common-institution",
   "metadata": {},
   "outputs": [],
   "source": [
    "companies = pd.read_csv('Companies.csv')\n",
    "comps = companies.iloc[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exterior-novel",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "comp_prices = pd.DataFrame()\n",
    "for comp in comps:\n",
    "    tick = yf.Ticker(comp)\n",
    "    dat = tick.history(start='2021-08-01', end='2021-08-31')\n",
    "    dat['Delta'] = dat['Close']-dat['Open']\n",
    "    dat['Ticker'] = comp\n",
    "    comp_prices = comp_prices.append(dat)\n",
    "comp_prices = comp_prices.reset_index(drop=False)\n",
    "df_prices=comp_prices[['Ticker','Date','Open','Close','Delta']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "green-dover",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "metric-perth",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
