{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "399a77e9-7e71-4468-a979-d940a0eaf2c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import praw\n",
    "from psaw import PushshiftAPI\n",
    "import datetime as dt\n",
    "import pandas as pd\n",
    "import shutil\n",
    "import os\n",
    "from tqdm.notebook import tqdm_notebook\n",
    "import json\n",
    "import time\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d45c6881-372c-4e05-928e-4d7b49cedf94",
   "metadata": {},
   "outputs": [],
   "source": [
    "REDDIT_CLIENT_ID = '4FEO91ch16g-P_n8AxU2_A'\n",
    "REDDIT_CLIENT_SECRET = 'Q2cyR53G5a6IpsSAzLbevNtBiITYhw'\n",
    "REDDIT_USER_AGENT = 'desktop:DSE203 (by u/Life_is_Life)'\n",
    "\n",
    "SUBREDDITS_TO_EXTRACT = (\n",
    "    # Sources:\n",
    "    #  - https://thehiveindex.com/topics/investing/platform/reddit/\n",
    "    #  - https://www.investopedia.com/reddit-top-investing-and-trading-communities-5189322\n",
    "    'stocks',\n",
    "    'wallstreetbets',\n",
    "    'pennystocks',\n",
    "    'investing',\n",
    "    'Wallstreetbetsnew',\n",
    "    'StockMarket',\n",
    "    'options',\n",
    "    'RobinHood',\n",
    "    'RobinHoodPennyStocks',\n",
    "    'weedstocks',\n",
    "    'smallstreetbets',\n",
    "    'SecurityAnalysis',\n",
    "    'CanadianInvestor',\n",
    "    'SPACs',\n",
    "    'InvestmentClub',\n",
    "    'ValueInvesting',\n",
    "    'investing_discussion',\n",
    "    'stonks',\n",
    "    'shroomstocks',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1c794616-aad0-477e-9c58-d828cb54b479",
   "metadata": {},
   "outputs": [],
   "source": [
    "reddit = praw.Reddit(\n",
    "    client_id = REDDIT_CLIENT_ID,\n",
    "    client_secret = REDDIT_CLIENT_SECRET,\n",
    "    user_agent = REDDIT_USER_AGENT\n",
    ")\n",
    "\n",
    "api = PushshiftAPI()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59ce6af9-8e09-4e55-b76b-f4f5d7260f3f",
   "metadata": {},
   "source": [
    "# Get top submissions (Reddit posts)\n",
    "\n",
    "Note: Make sure `top_submissions_and_comments/top_submissions` directory exists before running this. Any data inside this folder may be overwritten."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e5635e5e-2f46-41ae-9864-c1d562313f65",
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_search_q(stock_symbol):\n",
    "    companies_data = json.load(open('../dse203_final_project/companies.json'))\n",
    "    \n",
    "    search_q = list()\n",
    "    \n",
    "    search_q.append('$' + stock_symbol)\n",
    "    search_q.append(stock_symbol)\n",
    "    \n",
    "    for other_term in companies_data[stock_symbol]:\n",
    "        if ' ' in other_term:\n",
    "            search_q.append('\"' + other_term + '\"')\n",
    "        else:\n",
    "            search_q.append(other_term)\n",
    "    \n",
    "    return '|'.join(search_q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bba1cf92-7ca5-4a88-a836-c31a1204a876",
   "metadata": {},
   "outputs": [],
   "source": [
    "START_DATE = '2020-01-01'\n",
    "END_DATE = '2021-12-01'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c23f9890-1c6b-4a63-91e2-fdc0ecc82444",
   "metadata": {},
   "source": [
    "# Top Submissions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dd026c06-b17f-4b71-9e6b-dc4c18690b63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4256efb727df4f1ea934d4e7cd07d167",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1800 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Development\\DSE203_FinalProject\\venv\\lib\\site-packages\\psaw\\PushshiftAPI.py:192: UserWarning: Got non 200 code 429\n",
      "  warnings.warn(\"Got non 200 code %s\" % response.status_code)\n",
      "D:\\Development\\DSE203_FinalProject\\venv\\lib\\site-packages\\psaw\\PushshiftAPI.py:180: UserWarning: Unable to connect to pushshift.io. Retrying after backoff.\n",
      "  warnings.warn(\"Unable to connect to pushshift.io. Retrying after backoff.\")\n",
      "D:\\Development\\DSE203_FinalProject\\venv\\lib\\site-packages\\psaw\\PushshiftAPI.py:252: UserWarning: Not all PushShift shards are active. Query results may be incomplete\n",
      "  warnings.warn(shards_down_message)\n"
     ]
    }
   ],
   "source": [
    "LIMIT = 500\n",
    "companies_data = json.load(open('../dse203_final_project/companies.json'))\n",
    "month_begins = pd.date_range(START_DATE, END_DATE, freq='1MS')\n",
    "\n",
    "\n",
    "def get_top_sumbissions(stock_symbol, month_begin):\n",
    "    destination_json_file_path = os.path.join('top_submissions_and_comments', 'top_submissions', month_begin.strftime('%Y_%m_%d') + '__' + stock_symbol + '.json')\n",
    "    \n",
    "    if os.path.exists(destination_json_file_path):\n",
    "        return\n",
    "    \n",
    "    start_epoch = int(month_begin.to_pydatetime().timestamp())\n",
    "    end_epoch = int((month_begin + pd.offsets.MonthBegin() - pd.offsets.Second()).timestamp())\n",
    "        \n",
    "    top_submissions_gen = api.search_submissions(\n",
    "        after = start_epoch,\n",
    "        before = end_epoch,\n",
    "        q = construct_search_q(stock_symbol),\n",
    "        subreddit = ','.join(SUBREDDITS_TO_EXTRACT),\n",
    "        sort_type = 'num_comments',\n",
    "        sort = 'desc',\n",
    "        filter = ['id', 'url', 'subreddit', 'created', 'author', 'num_comments', 'num_crossposts', 'title', 'selftext'],\n",
    "        limit = LIMIT\n",
    "    )\n",
    "    \n",
    "    top_submissions = list()\n",
    "    for s in top_submissions_gen:\n",
    "        top_submissions.append(s.d_)\n",
    "    \n",
    "    with open(os.path.join('top_submissions_and_comments', 'top_submissions', month_begin.strftime('%Y_%m_%d') + '__' + stock_symbol + '.json'), 'w') as f:\n",
    "        json.dump(top_submissions, f, indent=4)\n",
    "\n",
    "\n",
    "with ThreadPoolExecutor() as executor:\n",
    "    futures = set()\n",
    "    for month_begin in month_begins:\n",
    "        for stock_symbol in companies_data:\n",
    "            futures.add(executor.submit(get_top_sumbissions, stock_symbol, month_begin))\n",
    "    \n",
    "    for future in tqdm_notebook(as_completed(futures), total=len(month_begins)*len(companies_data)):\n",
    "        future.result()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45f7492b-4b5c-496f-92f5-0cf7feea9063",
   "metadata": {},
   "source": [
    "# Top Comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a7eafadc-568f-4c65-888d-ec75441bf039",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce97003d263742a28c33ce69f92afa08",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1800 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Development\\DSE203_FinalProject\\venv\\lib\\site-packages\\psaw\\PushshiftAPI.py:192: UserWarning: Got non 200 code 429\n",
      "  warnings.warn(\"Got non 200 code %s\" % response.status_code)\n",
      "D:\\Development\\DSE203_FinalProject\\venv\\lib\\site-packages\\psaw\\PushshiftAPI.py:180: UserWarning: Unable to connect to pushshift.io. Retrying after backoff.\n",
      "  warnings.warn(\"Unable to connect to pushshift.io. Retrying after backoff.\")\n",
      "D:\\Development\\DSE203_FinalProject\\venv\\lib\\site-packages\\psaw\\PushshiftAPI.py:252: UserWarning: Not all PushShift shards are active. Query results may be incomplete\n",
      "  warnings.warn(shards_down_message)\n"
     ]
    }
   ],
   "source": [
    "LIMIT = 1_500\n",
    "companies_data = json.load(open('../dse203_final_project/companies.json'))\n",
    "month_begins = pd.date_range(START_DATE, END_DATE, freq='1MS')\n",
    "\n",
    "def get_top_comments(stock_symbol, month_begin):\n",
    "    destination_json_file_path = os.path.join('top_submissions_and_comments', 'top_comments', month_begin.strftime('%Y_%m_%d') + '__' + stock_symbol + '.json')\n",
    "    \n",
    "    if os.path.exists(destination_json_file_path):\n",
    "        return\n",
    "\n",
    "    start_epoch = int(month_begin.to_pydatetime().timestamp())\n",
    "    end_epoch = int((month_begin + pd.offsets.MonthBegin() - pd.offsets.Second()).timestamp())\n",
    "    \n",
    "    top_comments_gen = api.search_comments(\n",
    "        after = start_epoch,\n",
    "        before = end_epoch,\n",
    "        q = construct_search_q(stock_symbol),\n",
    "        subreddit = ','.join(SUBREDDITS_TO_EXTRACT),\n",
    "        sort_type = 'score',\n",
    "        sort = 'desc',\n",
    "        filter = ['id', 'url', 'subreddit', 'created', 'author', 'body', 'score'],\n",
    "        limit = LIMIT\n",
    "    )\n",
    "    \n",
    "    top_comments = list()\n",
    "    for s in top_comments_gen:\n",
    "        top_comments.append(s.d_)\n",
    "    \n",
    "    with open(destination_json_file_path, 'w') as f:\n",
    "        json.dump(top_comments, f, indent=4)\n",
    "        \n",
    "with ThreadPoolExecutor() as executor:\n",
    "    futures = set()\n",
    "    for month_begin in month_begins:\n",
    "        for stock_symbol in companies_data:\n",
    "            futures.add(executor.submit(get_top_comments, stock_symbol, month_begin))\n",
    "    \n",
    "    for future in tqdm_notebook(as_completed(futures), total=len(month_begins)*len(companies_data)):\n",
    "        try:\n",
    "            future.result()\n",
    "        except Exception:\n",
    "            print('An error occurred with one of the jobs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "aacc8202-3ab9-4155-a7f7-f11eabaf66bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_top_comments('AAPL', pd.to_datetime('2021-01-01'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
